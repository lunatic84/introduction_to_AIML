{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK3W0tk8kPlc"
      },
      "source": [
        "# 붓꽃 유형 분류 \n",
        "본 강의는 머신러닝을 사용하여 문제를 해결하는 전형적인 단계들과 전체적인 작업 구성을 이해하기 위한 것입니다. 이해를 돕기 위하여 꽃받침과 꽃잎의 길이와 너비를 기준으로 붓꽃의 유형을 판별(분류)하는 기능을 머신러닝을 이용하여 개발하고, 이를 웹/앱으로 사용할 수 있게 배포하는 예제를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nKN3Yudyse3"
      },
      "source": [
        "## 1. 머신러닝 패키지 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EreT36oQyse5"
      },
      "source": [
        "### 필요한 패키지 설치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlNOXUYLz80z"
      },
      "outputs": [],
      "source": [
        "pip install flaml[notebook] --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KA82I1X4ysfG"
      },
      "outputs": [],
      "source": [
        "pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gos7mWle0RqZ"
      },
      "source": [
        "### 라이브러리 패키지 불러오기\n",
        "이 단계는 필요에 따라 적절한 시점까지 미룰 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8_V-MOV5kPlo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import flaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeVbnjUwkPlp"
      },
      "source": [
        "## 2. 데이터집합 로드와 탐색"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL9tCpLwyse9"
      },
      "source": [
        "### Iris 데이터집합 이해\n",
        "https://archive.ics.uci.edu/ml/datasets/iris<br>\n",
        "꽃받침과 꽃잎의 길이와 너비에 따른 붓꽃 유형 분류 데이터\n",
        "\n",
        "4개의 feature와 1개의 레이블로 구성\n",
        "1. sepal length in cm\n",
        "2. sepal width in cm\n",
        "3. petal length in cm\n",
        "4. petal width in cm\n",
        "5. class: Setosa, Versicolour, Virginica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuM1-KhVyse-"
      },
      "source": [
        "### Iris 데이터집합 읽어들이기\n",
        "\n",
        "여기서는 Scikit-Learn이 제공하는 전처리된 데이터 사용.<br>\n",
        "sklearn.datasets.load_iris()를 호출하면 Iris 데이터집합을 반환함.<br>\n",
        "그 중 data는 4개의 feature들로 구성된 배열을, target은 label 배열을 의미."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daLalCzDkPlp",
        "outputId": "9a89be74-b58c-4570-eee9-fc2beb23d61e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[5.1, 3.5, 1.4, 0.2],\n",
              "        [4.9, 3. , 1.4, 0.2],\n",
              "        [4.7, 3.2, 1.3, 0.2],\n",
              "        [4.6, 3.1, 1.5, 0.2],\n",
              "        [5. , 3.6, 1.4, 0.2],\n",
              "        [5.4, 3.9, 1.7, 0.4],\n",
              "        [4.6, 3.4, 1.4, 0.3],\n",
              "        [5. , 3.4, 1.5, 0.2],\n",
              "        [4.4, 2.9, 1.4, 0.2],\n",
              "        [4.9, 3.1, 1.5, 0.1]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "iris.data[:10], iris.target[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFDiM3Wryse_"
      },
      "source": [
        "### 데이터집합 탐색"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "1I-tB-QDysfA",
        "outputId": "dda7922a-19e2-44c6-c910-ca15398baa84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb30e91bd0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(iris.target).value_counts().plot.pie(legend=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "g3n9MmNYysfB",
        "outputId": "ee0faf43-133a-45b7-e829-1c5711ce95df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb30e13450>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.Series(iris.target).value_counts().plot.bar(rot=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcW0OtUDysfB"
      },
      "source": [
        "### 훈련과 시험/검증을 위해 데이터집합 분할"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6jjicQq4kPls"
      },
      "outputs": [],
      "source": [
        " X, y = iris.data, iris.target\n",
        " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkOtValGkPl3"
      },
      "source": [
        "## 3. (분류) 모델 생성 및 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhPMLNmhysfD"
      },
      "source": [
        "(features, label, 문제유형 [, 탐색시간])을 제공하면 가장 적합한 모델을 자동으로 탐색해주는 FLAML이라는 도구를 사용하여 붓꽃 분류 모델을 생성하고 그 성능을 평가해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cmtQ3eDkPl4",
        "outputId": "26178c01-7b5d-430d-d41d-8fda4626cf7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[flaml.automl: 07-29 14:22:08] {2427} INFO - task = classification\n",
            "[flaml.automl: 07-29 14:22:08] {2429} INFO - Data split method: stratified\n",
            "[flaml.automl: 07-29 14:22:08] {2432} INFO - Evaluation method: cv\n",
            "[flaml.automl: 07-29 14:22:08] {2551} INFO - Minimizing error metric: log_loss\n",
            "[flaml.automl: 07-29 14:22:08] {2691} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth', 'lrl1']\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:08] {3127} INFO - Estimated sufficient time budget=564s. Estimated necessary time budget=14s.\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.1s,\testimator lgbm's best error=0.7083,\tbest estimator lgbm's best error=0.7083\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.2s,\testimator lgbm's best error=0.7083,\tbest estimator lgbm's best error=0.7083\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.2s,\testimator lgbm's best error=0.3866,\tbest estimator lgbm's best error=0.3866\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 3, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.3s,\testimator lgbm's best error=0.2341,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 4, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.4s,\testimator xgboost's best error=0.7361,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:08] {3179} INFO -  at 0.5s,\testimator lgbm's best error=0.2341,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:08] {2993} INFO - iteration 6, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:09] {3179} INFO -  at 1.7s,\testimator extra_tree's best error=0.4353,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:09] {2993} INFO - iteration 7, current learner rf\n",
            "[flaml.automl: 07-29 14:22:10] {3179} INFO -  at 2.9s,\testimator rf's best error=0.3287,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:10] {2993} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:11] {3179} INFO -  at 2.9s,\testimator lgbm's best error=0.2341,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:11] {2993} INFO - iteration 9, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:11] {3179} INFO -  at 3.0s,\testimator lgbm's best error=0.2341,\tbest estimator lgbm's best error=0.2341\n",
            "[flaml.automl: 07-29 14:22:11] {2993} INFO - iteration 10, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:11] {3179} INFO -  at 3.0s,\testimator lgbm's best error=0.2334,\tbest estimator lgbm's best error=0.2334\n",
            "[flaml.automl: 07-29 14:22:11] {2993} INFO - iteration 11, current learner rf\n",
            "[flaml.automl: 07-29 14:22:12] {3179} INFO -  at 4.2s,\testimator rf's best error=0.2390,\tbest estimator lgbm's best error=0.2334\n",
            "[flaml.automl: 07-29 14:22:12] {2993} INFO - iteration 12, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:13] {3179} INFO -  at 5.0s,\testimator xgboost's best error=0.7361,\tbest estimator lgbm's best error=0.2334\n",
            "[flaml.automl: 07-29 14:22:13] {2993} INFO - iteration 13, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:13] {3179} INFO -  at 5.6s,\testimator lgbm's best error=0.2178,\tbest estimator lgbm's best error=0.2178\n",
            "[flaml.automl: 07-29 14:22:13] {2993} INFO - iteration 14, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:13] {3179} INFO -  at 5.8s,\testimator lgbm's best error=0.2178,\tbest estimator lgbm's best error=0.2178\n",
            "[flaml.automl: 07-29 14:22:13] {2993} INFO - iteration 15, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:14] {3179} INFO -  at 6.2s,\testimator xgboost's best error=0.4205,\tbest estimator lgbm's best error=0.2178\n",
            "[flaml.automl: 07-29 14:22:14] {2993} INFO - iteration 16, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:14] {3179} INFO -  at 6.7s,\testimator lgbm's best error=0.2157,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:14] {2993} INFO - iteration 17, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:16] {3179} INFO -  at 8.0s,\testimator extra_tree's best error=0.3806,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:16] {2993} INFO - iteration 18, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:16] {3179} INFO -  at 8.1s,\testimator lgbm's best error=0.2157,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:16] {2993} INFO - iteration 19, current learner rf\n",
            "[flaml.automl: 07-29 14:22:17] {3179} INFO -  at 9.6s,\testimator rf's best error=0.2390,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:17] {2993} INFO - iteration 20, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:17] {3179} INFO -  at 9.8s,\testimator lgbm's best error=0.2157,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:17] {2993} INFO - iteration 21, current learner rf\n",
            "[flaml.automl: 07-29 14:22:19] {3179} INFO -  at 11.2s,\testimator rf's best error=0.2390,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:19] {2993} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:19] {3179} INFO -  at 11.7s,\testimator lgbm's best error=0.2157,\tbest estimator lgbm's best error=0.2157\n",
            "[flaml.automl: 07-29 14:22:19] {2993} INFO - iteration 23, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:21] {3179} INFO -  at 13.2s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:21] {2993} INFO - iteration 24, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:22] {3179} INFO -  at 14.6s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:22] {2993} INFO - iteration 25, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:23] {3179} INFO -  at 15.0s,\testimator xgboost's best error=0.1921,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:23] {2993} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:23] {3179} INFO -  at 15.3s,\testimator xgboost's best error=0.1921,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:23] {2993} INFO - iteration 27, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:23] {3179} INFO -  at 15.5s,\testimator xgboost's best error=0.1921,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:23] {2993} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:23] {3179} INFO -  at 15.9s,\testimator xgboost's best error=0.1921,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:23] {2993} INFO - iteration 29, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:24] {3179} INFO -  at 16.2s,\testimator xgboost's best error=0.1766,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:24] {2993} INFO - iteration 30, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:24] {3179} INFO -  at 16.7s,\testimator xgboost's best error=0.1766,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:24] {2993} INFO - iteration 31, current learner rf\n",
            "[flaml.automl: 07-29 14:22:26] {3179} INFO -  at 18.0s,\testimator rf's best error=0.2390,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:26] {2993} INFO - iteration 32, current learner rf\n",
            "[flaml.automl: 07-29 14:22:27] {3179} INFO -  at 19.5s,\testimator rf's best error=0.2089,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:27] {2993} INFO - iteration 33, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:28] {3179} INFO -  at 20.6s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:28] {2993} INFO - iteration 34, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:28] {3179} INFO -  at 20.6s,\testimator xgboost's best error=0.1766,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:28] {2993} INFO - iteration 35, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.1s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 36, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.3s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 37, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.4s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 38, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.5s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 39, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.6s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 40, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.7s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 41, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.8s,\testimator xgb_limitdepth's best error=0.2006,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 42, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:30] {3179} INFO -  at 22.8s,\testimator xgb_limitdepth's best error=0.1742,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:30] {2993} INFO - iteration 43, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:31] {3179} INFO -  at 22.9s,\testimator xgb_limitdepth's best error=0.1742,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:31] {2993} INFO - iteration 44, current learner rf\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.1s,\testimator rf's best error=0.2089,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 45, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.2s,\testimator xgb_limitdepth's best error=0.1742,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 46, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.2s,\testimator xgb_limitdepth's best error=0.1742,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 47, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.3s,\testimator xgb_limitdepth's best error=0.1742,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 48, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.4s,\testimator xgboost's best error=0.1717,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 49, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.5s,\testimator xgb_limitdepth's best error=0.1606,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 50, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.5s,\testimator xgboost's best error=0.1717,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 51, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.6s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 52, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.7s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 53, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.8s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 54, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:32] {3179} INFO -  at 24.8s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:32] {2993} INFO - iteration 55, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.0s,\testimator extra_tree's best error=0.3806,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 56, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.3s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 57, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.4s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 58, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.5s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 59, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.6s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 60, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:34] {3179} INFO -  at 26.7s,\testimator xgb_limitdepth's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:34] {2993} INFO - iteration 61, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:35] {3179} INFO -  at 27.2s,\testimator catboost's best error=0.1590,\tbest estimator catboost's best error=0.1590\n",
            "[flaml.automl: 07-29 14:22:35] {2993} INFO - iteration 62, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:35] {3179} INFO -  at 27.3s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:35] {2993} INFO - iteration 63, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:35] {3179} INFO -  at 27.3s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:35] {2993} INFO - iteration 64, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:35] {3179} INFO -  at 27.4s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:35] {2993} INFO - iteration 65, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:35] {3179} INFO -  at 27.5s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:35] {2993} INFO - iteration 66, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 27.9s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 67, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.0s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 68, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.1s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 69, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.2s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 70, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.7s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 71, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.8s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 72, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:36] {3179} INFO -  at 28.9s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:36] {2993} INFO - iteration 73, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.0s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 74, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.1s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 75, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.1s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 76, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.2s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 77, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.6s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 78, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.7s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 79, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.8s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 80, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.9s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 81, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:37] {3179} INFO -  at 29.9s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:37] {2993} INFO - iteration 82, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:38] {3179} INFO -  at 30.0s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:38] {2993} INFO - iteration 83, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.2s,\testimator extra_tree's best error=0.2969,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 84, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.3s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 85, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.4s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 86, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.6s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 87, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.6s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 88, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.7s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 89, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.8s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 90, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.8s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 91, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:39] {3179} INFO -  at 31.9s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:39] {2993} INFO - iteration 92, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:41] {3179} INFO -  at 33.3s,\testimator extra_tree's best error=0.2969,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:41] {2993} INFO - iteration 93, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:41] {3179} INFO -  at 33.3s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:41] {2993} INFO - iteration 94, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:41] {3179} INFO -  at 33.4s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:41] {2993} INFO - iteration 95, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:41] {3179} INFO -  at 33.5s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:41] {2993} INFO - iteration 96, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:46] {3179} INFO -  at 38.0s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:46] {2993} INFO - iteration 97, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:46] {3179} INFO -  at 38.1s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:46] {2993} INFO - iteration 98, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:47] {3179} INFO -  at 39.4s,\testimator extra_tree's best error=0.2969,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:47] {2993} INFO - iteration 99, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:47] {3179} INFO -  at 39.5s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:47] {2993} INFO - iteration 100, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:48] {3179} INFO -  at 40.6s,\testimator extra_tree's best error=0.2969,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:48] {2993} INFO - iteration 101, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:48] {3179} INFO -  at 40.7s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:48] {2993} INFO - iteration 102, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:48] {3179} INFO -  at 40.8s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:48] {2993} INFO - iteration 103, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:48] {3179} INFO -  at 40.8s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:48] {2993} INFO - iteration 104, current learner lgbm\n",
            "[flaml.automl: 07-29 14:22:48] {3179} INFO -  at 40.9s,\testimator lgbm's best error=0.2157,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:48] {2993} INFO - iteration 105, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:49] {3179} INFO -  at 41.0s,\testimator xgb_limitdepth's best error=0.1589,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:49] {2993} INFO - iteration 106, current learner xgboost\n",
            "[flaml.automl: 07-29 14:22:49] {3179} INFO -  at 41.0s,\testimator xgboost's best error=0.1717,\tbest estimator xgb_limitdepth's best error=0.1589\n",
            "[flaml.automl: 07-29 14:22:49] {2993} INFO - iteration 107, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:49] {3179} INFO -  at 41.2s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:49] {2993} INFO - iteration 108, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:49] {3179} INFO -  at 41.2s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:49] {2993} INFO - iteration 109, current learner extra_tree\n",
            "[flaml.automl: 07-29 14:22:50] {3179} INFO -  at 42.5s,\testimator extra_tree's best error=0.2969,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:50] {2993} INFO - iteration 110, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:50] {3179} INFO -  at 42.6s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:50] {2993} INFO - iteration 111, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:50] {3179} INFO -  at 42.7s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:50] {2993} INFO - iteration 112, current learner rf\n",
            "[flaml.automl: 07-29 14:22:52] {3179} INFO -  at 44.2s,\testimator rf's best error=0.2089,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:52] {2993} INFO - iteration 113, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:52] {3179} INFO -  at 44.3s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:52] {2993} INFO - iteration 114, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:52] {3179} INFO -  at 44.4s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:52] {2993} INFO - iteration 115, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:22:52] {3179} INFO -  at 44.5s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:52] {2993} INFO - iteration 116, current learner catboost\n",
            "[flaml.automl: 07-29 14:22:59] {3179} INFO -  at 51.5s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:22:59] {2993} INFO - iteration 117, current learner catboost\n",
            "[flaml.automl: 07-29 14:23:03] {3179} INFO -  at 54.9s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:03] {2993} INFO - iteration 118, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:03] {3179} INFO -  at 55.0s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:03] {2993} INFO - iteration 119, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:03] {3179} INFO -  at 55.1s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:03] {2993} INFO - iteration 120, current learner catboost\n",
            "[flaml.automl: 07-29 14:23:05] {3179} INFO -  at 57.9s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:05] {2993} INFO - iteration 121, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:06] {3179} INFO -  at 58.0s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:06] {2993} INFO - iteration 122, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:06] {3179} INFO -  at 58.1s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:06] {2993} INFO - iteration 123, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:06] {3179} INFO -  at 58.2s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:06] {2993} INFO - iteration 124, current learner xgb_limitdepth\n",
            "[flaml.automl: 07-29 14:23:06] {3179} INFO -  at 58.3s,\testimator xgb_limitdepth's best error=0.1480,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:06] {2993} INFO - iteration 125, current learner catboost\n",
            "[flaml.automl: 07-29 14:23:08] {3179} INFO -  at 60.1s,\testimator catboost's best error=0.1590,\tbest estimator xgb_limitdepth's best error=0.1480\n",
            "[flaml.automl: 07-29 14:23:08] {3439} INFO - retrain xgb_limitdepth for 0.0s\n",
            "[flaml.automl: 07-29 14:23:08] {3444} INFO - retrained model: XGBClassifier(colsample_bylevel=0.8477326194672863,\n",
            "              colsample_bytree=0.8046539624687794,\n",
            "              learning_rate=0.35414798323106667, max_depth=4,\n",
            "              min_child_weight=1.5958762043691384, n_estimators=31, n_jobs=-1,\n",
            "              objective='multi:softprob', reg_alpha=0.009487296541348228,\n",
            "              reg_lambda=0.6360698805551034, subsample=0.9408828540907503,\n",
            "              use_label_encoder=False, verbosity=0)\n",
            "[flaml.automl: 07-29 14:23:08] {2722} INFO - fit succeeded\n",
            "[flaml.automl: 07-29 14:23:08] {2724} INFO - Time taken to find the best model: 41.1529815196991\n"
          ]
        }
      ],
      "source": [
        "aml = flaml.AutoML()\n",
        "aml.fit(X_train, y_train, task=\"classification\", time_budget=60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5x0qDa3kPl4",
        "outputId": "aa0ece28-1158-4c87-e88d-02002e1f8d34"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = aml.predict(X_test)\n",
        "y_pred[:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ-RQ6XfkPl5",
        "outputId": "795447d6-cbdd-4c91-a2f1-d0b9e087c7a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       0.94      0.94      0.94        18\n",
            "           2       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.96        45\n",
            "   macro avg       0.96      0.96      0.96        45\n",
            "weighted avg       0.96      0.96      0.96        45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtY4VwQxysfF"
      },
      "source": [
        "## 4. 데이터 앱 작성과 배포"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kg1s-IHbysfH"
      },
      "outputs": [],
      "source": [
        "def predict(sepal_length, sepal_width, petal_length, petal_width):\n",
        "    data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])\n",
        "    return [\"Setosa\", \"Versicolour\", \"Virginica\"][aml.predict(data)[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "eSHzx_tYysfI",
        "outputId": "9c9d4a60-39eb-415f-9aa6-62bf79ec7b16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://12760.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://12760.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7feb1bc3dd90>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://12760.gradio.app')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "slider = gr.components.Slider\n",
        "means = iris.data.mean(axis=0)\n",
        "sepal_length= slider(maximum=10, value=round(means[0]), label='꽃받침 길이')\n",
        "sepal_width = slider(maximum=10, value=round(means[1]), label='꽃받침 너비')\n",
        "petal_length= slider(maximum=10, value=round(means[2]), label='꽃잎 길이')\n",
        "petal_width = slider(maximum=10, value=round(means[3]), label='꽃잎 너비')\n",
        "\n",
        "gr.Interface(predict, \n",
        "             [sepal_length, sepal_width, petal_length, petal_width], \"label\",\n",
        "             allow_flagging='never', live=True).launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JutdeKcQkPl6"
      },
      "source": [
        "## 복습\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV20kY5_kPl7"
      },
      "source": [
        "본 강의에서는 인공지능을 이용한 문제 해결의 전형적인 절차와 주요 구성 단계를 붓꽃 유형 분류 문제를 기준으로 소개하였습니다. Scikit-Learn이 제공하는 Iris 데이터집합과 FLAML이 제공하는 최적 머신러닝 모델 자동 판별 기능으로 매우 적은 노력으로 머신러닝을 활용한 문제 해결의 모든 단계를 효과적으로 해결할 수 있었습니다.<br><br>\n",
        "그러나 머신러닝을 활용하는 대부분의 문제는 다음과 같은 이유로 예제와 같이 손쉽게 해결되지는 않습니다.<br>\n",
        "1. 데이터집합이 머신러닝에 적합한 상태로 준비되어 있지 않은 경우가 많습니다. 데이터에 내재하는 패턴을 학습하기에 부족할 정도로 데이터가 적은 양이거나, 누락된 값(결측치)이 곳곳에 있거나, 데이터의 값이나 개수가 불균형적인 경우가 많습니다. 양질의 데이터가 있어야 좋은 머신러닝 모델을 얻을 수 있습니다. 이를 위해 다양한 데이터 공학(data engineering) 기법이 적용되어야 합니다.<br><br>\n",
        "2. 문제와 데이터 유형에 따라 매우 다른 유형의 머신러닝 알고리듬을 사용해야 하며, 동일한 알고리듬을 사용하더라도 그 알고리듬의 동작을 최적화하기 위해 다양한 하이퍼매개변수(hyperparameter)의 값을 찾아야할 때가 있습니다. 본 예제에서는 이 과정을 자동화할 수 있는 고급의 AutoML 도구인 FLAML을 사용하였습니다. (향후에는 AutoKeras도 사용하게 될 것입니다.) 그러나 실제 프로젝트에서는 FLAML이 찾아준 모델보다 더 좋은 성능의 모델을 필요로 하는 경우도 있고, 이를 위해 다양한 머신러닝 알고리듬과 그들의 동작 특성, 관련된 하이퍼매개변수, 그리고 이들을 최적화하는 방법을 학습해야 합니다.<br><br>\n",
        "3. 소프트웨어 프로젝트에서 머신러닝은 소프트웨어 시스템이 사용하는 하나 이상의 기능(예측)을 제공할 뿐 그 자체로 완성된 프로젝트가 아닙니다. 본 예제에서는 Gradio를 사용하여 웹 브라우저에서 사용할 수 있는 간단한 데이터 웹/앱을 매우 간편하게 개발하였습니다. 그러나 실제 프로젝트에서는 여러 머신러닝 모델과 관련된 데이터를 서버 환경에 유지하고, 클라이언트(웹이나 앱)로부터 발생하는 요청을 확장성 있고, 안전하고, 효율적으로 동작하게 지원하는 풀스택(full-stack) 개발을 요구하는 경우가 많습니다.<br>\n",
        "\n",
        "이러한 내용들은 AI/ML개론 학기가 진행됨에 따라 소프트웨어 개발 기법을 다루는 여러 교과목과 연계하여 차차 학습하게될 것입니다. 어떤 경우에든 머신러닝은 많은 흥미로운 문제들에 대한 매우 효과적인 해결책을 제공하는 매력적인 기술이며, 이 기술을 활용하는 데 고등수학이 필요하지도 않습니다. 열린 마음으로 즐겁게 하나씩 문제를 해결해 나가다보면 큰 발전을 이룰 수 있을 것입니다."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Module_7_(Iris_Type_Classification).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "925563f656975f3c1539e571bc5438640405dc9afd9ec87daa86319dfe46586d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
